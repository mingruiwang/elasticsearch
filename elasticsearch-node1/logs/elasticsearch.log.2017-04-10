[2017-04-10 09:24:55,988][INFO ][node                     ] [es-node1] version[1.7.3], pid[3660], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 09:24:56,000][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 09:24:56,090][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 09:24:56,116][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 09:24:58,540][INFO ][node                     ] [es-node1] initialized
[2017-04-10 09:24:58,540][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 09:24:58,810][INFO ][transport                ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/127.0.0.1:9300]}
[2017-04-10 09:24:58,829][INFO ][discovery                ] [es-node1] elasticsearch/jzXnJJfKQtS_a5kSNsHTVQ
[2017-04-10 09:25:15,116][INFO ][node                     ] [es-node1] version[1.7.3], pid[3698], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 09:25:15,117][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 09:25:15,201][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 09:25:15,236][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 09:25:17,366][INFO ][node                     ] [es-node1] initialized
[2017-04-10 09:25:17,366][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 09:25:17,481][ERROR][bootstrap                ] [es-node1] Exception
org.elasticsearch.transport.BindTransportException: Failed to bind to [9300]
	at org.elasticsearch.transport.netty.NettyTransport.bindServerBootstrap(NettyTransport.java:422)
	at org.elasticsearch.transport.netty.NettyTransport.doStart(NettyTransport.java:283)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.transport.TransportService.doStart(TransportService.java:153)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.node.internal.InternalNode.start(InternalNode.java:257)
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:160)
	at org.elasticsearch.bootstrap.Bootstrap.main(Bootstrap.java:248)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:32)
Caused by: org.elasticsearch.common.netty.channel.ChannelException: Failed to bind to: /0.0.0.0:9300
	at org.elasticsearch.common.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:272)
	at org.elasticsearch.transport.netty.NettyTransport$1.onPortNumber(NettyTransport.java:413)
	at org.elasticsearch.common.transport.PortsRange.iterate(PortsRange.java:58)
	at org.elasticsearch.transport.netty.NettyTransport.bindServerBootstrap(NettyTransport.java:409)
	... 8 more
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss$RegisterTask.run(NioServerBoss.java:193)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue(AbstractNioSelector.java:391)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:315)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-04-10 09:25:17,494][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 09:25:17,504][INFO ][node                     ] [es-node1] stopped
[2017-04-10 09:25:17,504][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 09:25:17,506][INFO ][node                     ] [es-node1] closed
[2017-04-10 09:25:28,829][WARN ][discovery                ] [es-node1] waited for 30s and no initial state was set by the discovery
[2017-04-10 09:25:28,835][INFO ][http                     ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/127.0.0.1:9200]}
[2017-04-10 09:25:28,835][INFO ][node                     ] [es-node1] started
[2017-04-10 09:25:29,728][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:29,787][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:31,783][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:31,784][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:31,895][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:31,898][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:48,263][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:48,266][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:49,290][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:49,291][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:49,420][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:49,425][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:49,468][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:49,570][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:49,573][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:50,390][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:50,400][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:50,486][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:50,596][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:50,599][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:50,670][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:50,780][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:50,784][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:51,172][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:51,181][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:51,538][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:51,539][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:51,655][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:51,663][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:51,735][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:51,736][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:51,842][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:51,855][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:52,304][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:52,308][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:52,405][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:52,516][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:52,522][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:53,074][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:53,091][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:53,171][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:53,172][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:53,290][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:53,297][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:25:59,731][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:25:59,788][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:01,784][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:01,784][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:01,896][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:01,899][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:07,492][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:07,494][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:07,596][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:07,599][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:12,365][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:12,368][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:12,476][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:12,569][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:12,572][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:12,862][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:12,863][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:12,969][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:12,974][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:13,042][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:13,150][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:13,155][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:13,238][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:13,240][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:13,334][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:13,337][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:14,729][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:14,730][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:14,832][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:14,839][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:18,264][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:18,267][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:19,291][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:19,292][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:19,421][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:19,425][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:19,468][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:19,570][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:19,574][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:20,390][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:20,400][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:20,486][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:20,596][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:20,599][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:20,671][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:20,781][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:20,784][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:21,172][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:21,181][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:21,542][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:21,542][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:21,655][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:21,664][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:21,736][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:21,737][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:21,842][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:21,860][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:22,305][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:22,308][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:22,406][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:22,517][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:22,523][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:23,074][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:23,092][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:23,171][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:23,173][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:23,290][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:23,297][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:34,842][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:34,843][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:37,493][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:37,496][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:37,597][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:37,600][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:42,365][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:42,368][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:42,476][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:42,570][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:42,573][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:42,864][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:42,864][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:42,969][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:42,974][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:43,043][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:43,150][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:43,156][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:43,239][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:43,240][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:43,334][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:43,337][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:44,730][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:44,731][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:44,833][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:26:44,839][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:26:44,840][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:27:04,843][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:27:04,844][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:27:14,840][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:27:14,844][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:27:44,845][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 09:29:28,569][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:28,580][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:29,993][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:30,095][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:30,106][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:30,216][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:30,316][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:30,321][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:30,795][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:30,795][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:30,889][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:30,893][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:30,981][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,104][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,108][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,160][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,254][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,260][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,448][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,543][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,546][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,637][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,734][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,737][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,789][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,884][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,888][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:31,944][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:32,038][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:32,044][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:32,267][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:32,362][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:32,366][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:32,450][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:32,452][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:32,547][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:32,549][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:32,876][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:32,876][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:32,968][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:32,973][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:33,057][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:33,057][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:33,151][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:33,154][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:33,232][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:33,332][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:33,332][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:33,383][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:33,486][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:33,489][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:33,912][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:33,912][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,020][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,024][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,087][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,088][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,183][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,186][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,253][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,254][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,254][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,345][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,349][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,641][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,643][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,737][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,740][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,859][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,955][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:34,962][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:35,059][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:35,059][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:35,153][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:35,156][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:36,915][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:36,916][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:37,011][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:37,013][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:37,628][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:37,635][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:37,700][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:37,701][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:37,792][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:37,796][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:37,903][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:37,903][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:37,995][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:37,997][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:38,255][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:38,261][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:38,353][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:38,355][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:38,443][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:38,541][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:38,546][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:38,619][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:38,619][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:38,749][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:38,759][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:29:39,033][INFO ][cluster.service          ] [es-node1] detected_master [Daytripper][Yuh_2nXLQSiPGPURqWEsjg][v-c7-es][inet[/192.168.8.81:9301]], added {[Daytripper][Yuh_2nXLQSiPGPURqWEsjg][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-receive(from master [[Daytripper][Yuh_2nXLQSiPGPURqWEsjg][v-c7-es][inet[/192.168.8.81:9301]]])
[2017-04-10 09:29:39,898][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-04-10 09:29:39,899][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-04-10 09:29:39,947][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-04-10 09:36:04,492][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 09:36:04,645][INFO ][node                     ] [es-node1] stopped
[2017-04-10 09:36:04,645][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 09:36:04,715][INFO ][node                     ] [es-node1] closed
[2017-04-10 09:37:01,317][INFO ][node                     ] [es-node1] version[1.7.3], pid[2450], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 09:37:01,328][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 09:37:01,441][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 09:37:01,465][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 09:37:03,961][INFO ][node                     ] [es-node1] initialized
[2017-04-10 09:37:03,962][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 09:37:04,090][INFO ][transport                ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/127.0.0.1:9300]}
[2017-04-10 09:37:04,107][INFO ][discovery                ] [es-node1] elasticsearch/m72BCYzbRaWnnxAzrlgCmA
[2017-04-10 09:37:34,108][WARN ][discovery                ] [es-node1] waited for 30s and no initial state was set by the discovery
[2017-04-10 09:37:34,114][INFO ][http                     ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/127.0.0.1:9200]}
[2017-04-10 09:37:34,114][INFO ][node                     ] [es-node1] started
[2017-04-10 09:37:57,813][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:37:57,826][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:03,622][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:03,623][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:03,719][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:03,724][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:05,753][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:05,754][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:05,874][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:05,875][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:05,966][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:06,052][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:06,070][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:06,091][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:06,191][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:06,198][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:06,677][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:06,774][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:06,775][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:06,820][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:06,916][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:06,919][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:06,959][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:06,964][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,058][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,065][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,106][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,106][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,205][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,212][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,468][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,468][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,560][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,565][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,633][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,736][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,739][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,771][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,772][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,869][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,873][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,929][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:07,931][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:08,028][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:08,032][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:08,192][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:08,291][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:08,300][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:08,358][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:08,453][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:08,456][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:08,523][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:08,623][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:08,626][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:08,926][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:08,927][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,023][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,028][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,083][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,084][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,180][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,183][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,235][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,326][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,330][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,371][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,373][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,468][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,472][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,532][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,627][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,632][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,688][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,782][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:09,785][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:11,972][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:11,972][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:12,076][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:12,085][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:12,198][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:12,284][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:12,286][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 09:38:24,173][INFO ][cluster.service          ] [es-node1] detected_master [Matt Murdock][7yxJE4_ZQZqHu6rcFTh6mw][v-c7-es][inet[/192.168.8.81:9301]], added {[Matt Murdock][7yxJE4_ZQZqHu6rcFTh6mw][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-receive(from master [[Matt Murdock][7yxJE4_ZQZqHu6rcFTh6mw][v-c7-es][inet[/192.168.8.81:9301]]])
[2017-04-10 09:38:24,995][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-04-10 09:38:25,005][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-04-10 09:38:25,022][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-04-10 12:35:34,995][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 12:35:35,123][INFO ][node                     ] [es-node1] stopped
[2017-04-10 12:35:35,123][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 12:35:35,125][INFO ][node                     ] [es-node1] closed
[2017-04-10 12:36:53,255][INFO ][node                     ] [es-node1] version[1.7.3], pid[2383], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 12:36:53,262][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 12:36:53,355][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 12:36:53,383][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 12:36:55,747][INFO ][node                     ] [es-node1] initialized
[2017-04-10 12:36:55,747][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 12:36:55,999][INFO ][transport                ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/127.0.0.1:9300]}
[2017-04-10 12:36:56,017][INFO ][discovery                ] [es-node1] elasticsearch/1u3kVyM6Tze-FjysArHnGA
[2017-04-10 12:37:26,017][WARN ][discovery                ] [es-node1] waited for 30s and no initial state was set by the discovery
[2017-04-10 12:37:26,023][INFO ][http                     ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/127.0.0.1:9200]}
[2017-04-10 12:37:26,023][INFO ][node                     ] [es-node1] started
[2017-04-10 12:38:16,144][INFO ][cluster.service          ] [es-node1] detected_master [Firearm][dMwjRkkaQW-J0t5aEHnOOw][v-c7-es][inet[/192.168.8.81:9301]], added {[Firearm][dMwjRkkaQW-J0t5aEHnOOw][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-receive(from master [[Firearm][dMwjRkkaQW-J0t5aEHnOOw][v-c7-es][inet[/192.168.8.81:9301]]])
[2017-04-10 12:38:16,761][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-04-10 12:38:16,772][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-04-10 12:38:16,827][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-04-10 13:11:48,142][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 13:11:48,278][INFO ][node                     ] [es-node1] stopped
[2017-04-10 13:11:48,278][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 13:11:48,279][INFO ][node                     ] [es-node1] closed
[2017-04-10 13:13:58,089][INFO ][node                     ] [es-node1] version[1.7.3], pid[2699], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 13:13:58,089][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 13:13:58,185][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 13:13:58,212][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 13:14:00,417][INFO ][node                     ] [es-node1] initialized
[2017-04-10 13:14:00,417][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 13:14:00,577][ERROR][bootstrap                ] [es-node1] Exception
org.elasticsearch.transport.BindTransportException: Failed to bind to [9300]
	at org.elasticsearch.transport.netty.NettyTransport.bindServerBootstrap(NettyTransport.java:422)
	at org.elasticsearch.transport.netty.NettyTransport.doStart(NettyTransport.java:283)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.transport.TransportService.doStart(TransportService.java:153)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.node.internal.InternalNode.start(InternalNode.java:257)
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:160)
	at org.elasticsearch.bootstrap.Bootstrap.main(Bootstrap.java:248)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:32)
Caused by: org.elasticsearch.common.netty.channel.ChannelException: Failed to bind to: /0.0.0.0:9300
	at org.elasticsearch.common.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:272)
	at org.elasticsearch.transport.netty.NettyTransport$1.onPortNumber(NettyTransport.java:413)
	at org.elasticsearch.common.transport.PortsRange.iterate(PortsRange.java:58)
	at org.elasticsearch.transport.netty.NettyTransport.bindServerBootstrap(NettyTransport.java:409)
	... 8 more
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss$RegisterTask.run(NioServerBoss.java:193)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue(AbstractNioSelector.java:391)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:315)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-04-10 13:14:00,589][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 13:14:00,602][INFO ][node                     ] [es-node1] stopped
[2017-04-10 13:14:00,602][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 13:14:00,606][INFO ][node                     ] [es-node1] closed
[2017-04-10 13:16:06,138][INFO ][node                     ] [es-node1] version[1.7.3], pid[2729], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 13:16:06,138][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 13:16:06,239][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 13:16:06,281][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 13:16:08,528][INFO ][node                     ] [es-node1] initialized
[2017-04-10 13:16:08,529][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 13:16:08,656][ERROR][bootstrap                ] [es-node1] Exception
org.elasticsearch.transport.BindTransportException: Failed to bind to [9300]
	at org.elasticsearch.transport.netty.NettyTransport.bindServerBootstrap(NettyTransport.java:422)
	at org.elasticsearch.transport.netty.NettyTransport.doStart(NettyTransport.java:283)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.transport.TransportService.doStart(TransportService.java:153)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.node.internal.InternalNode.start(InternalNode.java:257)
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:160)
	at org.elasticsearch.bootstrap.Bootstrap.main(Bootstrap.java:248)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:32)
Caused by: org.elasticsearch.common.netty.channel.ChannelException: Failed to bind to: /0.0.0.0:9300
	at org.elasticsearch.common.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:272)
	at org.elasticsearch.transport.netty.NettyTransport$1.onPortNumber(NettyTransport.java:413)
	at org.elasticsearch.common.transport.PortsRange.iterate(PortsRange.java:58)
	at org.elasticsearch.transport.netty.NettyTransport.bindServerBootstrap(NettyTransport.java:409)
	... 8 more
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss$RegisterTask.run(NioServerBoss.java:193)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue(AbstractNioSelector.java:391)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:315)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-04-10 13:16:08,658][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 13:16:08,659][INFO ][node                     ] [es-node1] stopped
[2017-04-10 13:16:08,659][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 13:16:08,663][INFO ][node                     ] [es-node1] closed
[2017-04-10 13:16:53,062][INFO ][node                     ] [es-node1] version[1.7.3], pid[2770], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 13:16:53,062][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 13:16:53,160][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 13:16:53,186][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 13:16:55,404][INFO ][node                     ] [es-node1] initialized
[2017-04-10 13:16:55,404][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 13:16:55,515][INFO ][transport                ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/127.0.0.1:9300]}
[2017-04-10 13:16:55,521][INFO ][discovery                ] [es-node1] elasticsearch/UrCigTGCTneX3NiPU3K89g
[2017-04-10 13:17:25,522][WARN ][discovery                ] [es-node1] waited for 30s and no initial state was set by the discovery
[2017-04-10 13:17:25,527][INFO ][http                     ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/127.0.0.1:9200]}
[2017-04-10 13:17:25,527][INFO ][node                     ] [es-node1] started
[2017-04-10 13:18:15,613][INFO ][cluster.service          ] [es-node1] detected_master [Bible John][7cd0OXIoSu64OwCc4YzyMQ][v-c7-es][inet[/192.168.8.81:9301]], added {[Bible John][7cd0OXIoSu64OwCc4YzyMQ][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-receive(from master [[Bible John][7cd0OXIoSu64OwCc4YzyMQ][v-c7-es][inet[/192.168.8.81:9301]]])
[2017-04-10 13:18:16,394][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-04-10 13:18:16,394][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-04-10 13:18:16,395][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-04-10 14:34:49,498][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 14:34:49,546][INFO ][discovery.zen            ] [es-node1] master_left [[Bible John][7cd0OXIoSu64OwCc4YzyMQ][v-c7-es][inet[/192.168.8.81:9301]]], reason [shut_down]
[2017-04-10 14:34:49,550][WARN ][discovery.zen            ] [es-node1] master left (reason = shut_down), current nodes: {[es-node1][UrCigTGCTneX3NiPU3K89g][v-c7-es][inet[/127.0.0.1:9300]],}
[2017-04-10 14:34:49,594][INFO ][discovery.zen            ] [es-node1] master_left [[Bible John][7cd0OXIoSu64OwCc4YzyMQ][v-c7-es][inet[/192.168.8.81:9301]]], reason [transport disconnected]
[2017-04-10 14:34:49,594][INFO ][cluster.service          ] [es-node1] removed {[Bible John][7cd0OXIoSu64OwCc4YzyMQ][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-master_failed ([Bible John][7cd0OXIoSu64OwCc4YzyMQ][v-c7-es][inet[/192.168.8.81:9301]])
[2017-04-10 14:34:49,660][INFO ][node                     ] [es-node1] stopped
[2017-04-10 14:34:49,661][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 14:34:49,663][INFO ][node                     ] [es-node1] closed
[2017-04-10 14:35:34,004][INFO ][node                     ] [es-node1] version[1.7.3], pid[2389], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 14:35:34,015][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 14:35:34,111][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 14:35:34,137][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 14:35:36,620][INFO ][node                     ] [es-node1] initialized
[2017-04-10 14:35:36,620][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 14:35:36,783][INFO ][transport                ] [es-node1] bound_address {inet[/192.168.8.81:9300]}, publish_address {inet[/192.168.8.81:9300]}
[2017-04-10 14:35:36,800][INFO ][discovery                ] [es-node1] elasticsearch/mYk0B2QcQNyvq7fcTD4NCQ
[2017-04-10 14:36:06,801][WARN ][discovery                ] [es-node1] waited for 30s and no initial state was set by the discovery
[2017-04-10 14:36:06,807][INFO ][http                     ] [es-node1] bound_address {inet[/192.168.8.81:9200]}, publish_address {inet[/192.168.8.81:9200]}
[2017-04-10 14:36:06,807][INFO ][node                     ] [es-node1] started
[2017-04-10 14:36:22,218][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:36:22,219][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:36:22,703][INFO ][node                     ] [es-node1] version[1.7.3], pid[2426], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 14:36:22,703][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 14:36:22,846][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 14:36:22,924][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 14:36:25,111][INFO ][node                     ] [es-node1] initialized
[2017-04-10 14:36:25,112][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 14:36:25,211][ERROR][bootstrap                ] [es-node1] Exception
org.elasticsearch.transport.BindTransportException: Failed to bind to [9300]
	at org.elasticsearch.transport.netty.NettyTransport.bindServerBootstrap(NettyTransport.java:422)
	at org.elasticsearch.transport.netty.NettyTransport.doStart(NettyTransport.java:283)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.transport.TransportService.doStart(TransportService.java:153)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.node.internal.InternalNode.start(InternalNode.java:257)
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:160)
	at org.elasticsearch.bootstrap.Bootstrap.main(Bootstrap.java:248)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:32)
Caused by: org.elasticsearch.common.netty.channel.ChannelException: Failed to bind to: /192.168.8.81:9300
	at org.elasticsearch.common.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:272)
	at org.elasticsearch.transport.netty.NettyTransport$1.onPortNumber(NettyTransport.java:413)
	at org.elasticsearch.common.transport.PortsRange.iterate(PortsRange.java:58)
	at org.elasticsearch.transport.netty.NettyTransport.bindServerBootstrap(NettyTransport.java:409)
	... 8 more
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss$RegisterTask.run(NioServerBoss.java:193)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue(AbstractNioSelector.java:391)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:315)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-04-10 14:36:25,224][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 14:36:25,238][INFO ][node                     ] [es-node1] stopped
[2017-04-10 14:36:25,238][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 14:36:25,242][INFO ][node                     ] [es-node1] closed
[2017-04-10 14:36:42,175][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:36:42,176][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:36:44,215][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 14:36:44,219][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:36:44,226][INFO ][node                     ] [es-node1] stopped
[2017-04-10 14:36:44,226][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 14:36:44,232][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.elasticsearch.common.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.elasticsearch.common.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.elasticsearch.common.netty.channel.Channels.write(Channels.java:725)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:195)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.TransportAction$ThreadedActionListener$2.run(TransportAction.java:137)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-04-10 14:36:44,235][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.elasticsearch.common.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.elasticsearch.common.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.elasticsearch.common.netty.channel.Channels.write(Channels.java:725)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:195)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.TransportAction$ThreadedActionListener$2.run(TransportAction.java:137)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-04-10 14:36:44,237][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.elasticsearch.common.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.elasticsearch.common.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.elasticsearch.common.netty.channel.Channels.write(Channels.java:725)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:195)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.TransportAction$ThreadedActionListener$2.run(TransportAction.java:137)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-04-10 14:36:44,238][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.elasticsearch.common.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.elasticsearch.common.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.elasticsearch.common.netty.channel.Channels.write(Channels.java:725)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:195)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.TransportAction$ThreadedActionListener$2.run(TransportAction.java:137)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-04-10 14:36:44,238][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.elasticsearch.common.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.elasticsearch.common.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:781)
	at org.elasticsearch.common.netty.channel.Channels.write(Channels.java:725)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.doEncode(OneToOneEncoder.java:71)
	at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:59)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.handleDownstream(HttpPipeliningHandler.java:87)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)
	at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)
	at org.elasticsearch.http.netty.NettyHttpChannel.sendResponse(NettyHttpChannel.java:195)
	at org.elasticsearch.rest.action.support.RestActionListener.onFailure(RestActionListener.java:60)
	at org.elasticsearch.action.support.TransportAction$ThreadedActionListener$2.run(TransportAction.java:137)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-04-10 14:36:44,239][INFO ][node                     ] [es-node1] closed
[2017-04-10 14:37:13,514][INFO ][node                     ] [es-node1] version[1.7.3], pid[2473], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 14:37:13,515][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 14:37:13,618][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 14:37:13,650][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 14:37:15,849][INFO ][node                     ] [es-node1] initialized
[2017-04-10 14:37:15,849][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 14:37:16,007][INFO ][transport                ] [es-node1] bound_address {inet[/192.168.8.81:9300]}, publish_address {inet[/192.168.8.81:9300]}
[2017-04-10 14:37:16,023][INFO ][discovery                ] [es-node1] elasticsearch/XHIe7rG5Q_OQKcuDK36hOQ
[2017-04-10 14:37:46,024][WARN ][discovery                ] [es-node1] waited for 30s and no initial state was set by the discovery
[2017-04-10 14:37:46,030][INFO ][http                     ] [es-node1] bound_address {inet[/192.168.8.81:9200]}, publish_address {inet[/192.168.8.81:9200]}
[2017-04-10 14:37:46,030][INFO ][node                     ] [es-node1] started
[2017-04-10 14:37:54,654][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:54,686][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:56,122][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:56,125][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:56,219][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:56,223][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:56,309][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:56,412][INFO ][discovery.zen            ] [es-node1] failed to send join request to master [[Azazel][JL7MS1WNQL2s9cXNxw2elw][v-c7-es][inet[/192.168.8.81:9301]]], reason [RemoteTransportException[[Azazel][inet[/192.168.8.81:9301]][internal:discovery/zen/join]]; nested: ElasticsearchIllegalStateException[Node [[Azazel][JL7MS1WNQL2s9cXNxw2elw][v-c7-es][inet[/192.168.8.81:9301]]] not master for join request from [[es-node1][XHIe7rG5Q_OQKcuDK36hOQ][v-c7-es][inet[/192.168.8.81:9300]]]]; ], tried [3] times
[2017-04-10 14:37:56,432][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:56,435][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:56,468][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:56,470][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:56,594][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:56,597][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:57,849][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:37:57,861][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:01,744][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:01,745][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:01,858][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:01,858][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:02,409][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:02,410][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:02,510][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:02,519][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:02,590][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:02,689][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:02,695][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:02,776][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:02,874][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:02,880][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:02,923][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,022][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,025][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,113][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,205][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,208][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,481][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,483][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,572][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,575][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,625][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,723][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,728][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,789][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,892][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,896][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,954][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:03,955][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:04,051][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:04,058][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:04,395][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:04,504][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:04,509][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:04,562][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:04,660][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:04,669][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:04,740][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:04,842][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:04,846][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:04,904][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:05,019][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:05,025][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:05,083][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:05,175][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:05,180][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:07,577][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:07,578][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:07,680][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:07,686][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:07,724][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:07,726][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:07,828][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:07,831][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:07,913][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:08,020][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:08,023][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:24,532][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:24,533][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:24,627][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:24,631][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:24,683][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:24,715][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:25,101][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,103][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,198][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,202][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,274][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,368][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,375][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,438][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,438][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,534][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,539][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,761][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,888][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,892][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:25,931][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:26,026][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:26,029][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:26,071][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:26,072][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:26,122][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:26,125][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:26,180][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:26,189][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:26,219][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:26,223][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:26,241][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:26,310][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:26,335][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:26,339][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 14:38:26,433][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:26,437][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:26,468][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:26,472][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:26,595][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:26,598][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:27,861][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:27,864][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:31,745][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:31,746][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:31,859][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:31,861][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:32,410][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:32,412][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:32,511][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:32,519][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:32,590][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:32,690][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:32,696][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:32,776][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:32,875][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:32,880][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:32,924][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,022][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,025][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,114][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,205][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,209][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,484][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,485][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,572][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,575][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,625][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,723][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,728][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,790][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,893][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,896][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,955][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:33,959][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:34,052][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:34,059][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:34,395][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:34,504][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:34,509][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:34,562][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:34,660][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:34,670][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:34,741][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:34,842][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:34,847][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:34,905][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:35,020][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:35,026][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:35,085][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:35,176][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:35,180][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 14:38:36,430][INFO ][cluster.service          ] [es-node1] detected_master [Azazel][JL7MS1WNQL2s9cXNxw2elw][v-c7-es][inet[/192.168.8.81:9301]], added {[Azazel][JL7MS1WNQL2s9cXNxw2elw][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-receive(from master [[Azazel][JL7MS1WNQL2s9cXNxw2elw][v-c7-es][inet[/192.168.8.81:9301]]])
[2017-04-10 14:38:37,417][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-04-10 14:38:37,417][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-04-10 14:38:37,453][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-04-10 15:22:42,808][INFO ][discovery.zen            ] [es-node1] master_left [[Azazel][JL7MS1WNQL2s9cXNxw2elw][v-c7-es][inet[/192.168.8.81:9301]]], reason [shut_down]
[2017-04-10 15:22:42,808][WARN ][discovery.zen            ] [es-node1] master left (reason = shut_down), current nodes: {[es-node1][XHIe7rG5Q_OQKcuDK36hOQ][v-c7-es][inet[/192.168.8.81:9300]],}
[2017-04-10 15:22:42,808][INFO ][cluster.service          ] [es-node1] removed {[Azazel][JL7MS1WNQL2s9cXNxw2elw][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-master_failed ([Azazel][JL7MS1WNQL2s9cXNxw2elw][v-c7-es][inet[/192.168.8.81:9301]])
[2017-04-10 15:22:57,037][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 15:22:57,064][INFO ][node                     ] [es-node1] stopped
[2017-04-10 15:22:57,064][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 15:22:57,066][INFO ][node                     ] [es-node1] closed
[2017-04-10 15:24:55,959][INFO ][node                     ] [es-node1] version[1.7.3], pid[2685], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 15:24:55,960][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 15:24:56,036][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 15:24:56,060][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 15:24:58,170][INFO ][node                     ] [es-node1] initialized
[2017-04-10 15:24:58,170][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 15:24:58,230][INFO ][transport                ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/127.0.0.1:9300]}
[2017-04-10 15:24:58,248][INFO ][discovery                ] [es-node1] elasticsearch/ONiDzWfKQYWS3FBDZwiw6g
[2017-04-10 15:25:28,248][WARN ][discovery                ] [es-node1] waited for 30s and no initial state was set by the discovery
[2017-04-10 15:25:28,254][INFO ][http                     ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/127.0.0.1:9200]}
[2017-04-10 15:25:28,255][INFO ][node                     ] [es-node1] started
[2017-04-10 15:25:38,351][INFO ][cluster.service          ] [es-node1] new_master [es-node1][ONiDzWfKQYWS3FBDZwiw6g][v-c7-es][inet[/127.0.0.1:9300]], reason: zen-disco-join (elected_as_master)
[2017-04-10 15:25:41,344][INFO ][cluster.service          ] [es-node1] added {[Adonis][uVuMjYp2QU6RTBC3jdFxXA][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-receive(join from node[[Adonis][uVuMjYp2QU6RTBC3jdFxXA][v-c7-es][inet[/192.168.8.81:9301]]])
[2017-04-10 15:25:41,497][INFO ][gateway                  ] [es-node1] recovered [3] indices into cluster_state
[2017-04-10 15:25:42,943][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-04-10 15:25:42,943][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-04-10 15:25:42,944][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-04-10 15:40:46,515][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 15:40:46,575][INFO ][node                     ] [es-node1] stopped
[2017-04-10 15:40:46,575][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 15:40:46,577][INFO ][node                     ] [es-node1] closed
[2017-04-10 15:42:24,303][INFO ][node                     ] [es-node1] version[1.7.3], pid[2893], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 15:42:24,304][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 15:42:24,396][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 15:42:24,422][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 15:42:26,627][INFO ][node                     ] [es-node1] initialized
[2017-04-10 15:42:26,627][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 15:42:26,789][INFO ][transport                ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/127.0.0.1:9300]}
[2017-04-10 15:42:26,797][INFO ][discovery                ] [es-node1] elasticsearch/2HjsLqgrR-iN6v-O6gj0wA
[2017-04-10 15:42:56,797][WARN ][discovery                ] [es-node1] waited for 30s and no initial state was set by the discovery
[2017-04-10 15:42:56,803][INFO ][http                     ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/127.0.0.1:9200]}
[2017-04-10 15:42:56,803][INFO ][node                     ] [es-node1] started
[2017-04-10 15:43:06,927][INFO ][cluster.service          ] [es-node1] new_master [es-node1][2HjsLqgrR-iN6v-O6gj0wA][v-c7-es][inet[/127.0.0.1:9300]], reason: zen-disco-join (elected_as_master)
[2017-04-10 15:43:09,846][INFO ][cluster.service          ] [es-node1] added {[Phade][8ZVecqKqQkejIfmPsH5mOQ][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-receive(join from node[[Phade][8ZVecqKqQkejIfmPsH5mOQ][v-c7-es][inet[/192.168.8.81:9301]]])
[2017-04-10 15:43:10,018][INFO ][gateway                  ] [es-node1] recovered [3] indices into cluster_state
[2017-04-10 15:43:11,346][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-04-10 15:43:11,346][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-04-10 15:43:11,348][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-04-10 16:32:47,296][INFO ][cluster.metadata         ] [es-node1] [my_index] deleting index
[2017-04-10 16:33:10,398][INFO ][cluster.metadata         ] [es-node1] [iii] creating index, cause [api], templates [], shards [5]/[1], mappings []
[2017-04-10 16:42:08,345][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 16:42:08,422][INFO ][node                     ] [es-node1] stopped
[2017-04-10 16:42:08,422][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 16:42:08,425][INFO ][node                     ] [es-node1] closed
[2017-04-10 16:42:47,803][INFO ][node                     ] [es-node1] version[1.7.3], pid[3113], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 16:42:47,804][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 16:42:47,881][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 16:42:47,906][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 16:42:50,073][INFO ][node                     ] [es-node1] initialized
[2017-04-10 16:42:50,073][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 16:42:50,184][INFO ][transport                ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/127.0.0.1:9300]}
[2017-04-10 16:42:50,194][INFO ][discovery                ] [es-node1] elasticsearch/HL4iLvfARBOk_2F-xXmGOA
[2017-04-10 16:43:20,195][WARN ][discovery                ] [es-node1] waited for 30s and no initial state was set by the discovery
[2017-04-10 16:43:20,201][INFO ][http                     ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/127.0.0.1:9200]}
[2017-04-10 16:43:20,201][INFO ][node                     ] [es-node1] started
[2017-04-10 16:43:30,269][INFO ][cluster.service          ] [es-node1] detected_master [Phade][8ZVecqKqQkejIfmPsH5mOQ][v-c7-es][inet[/192.168.8.81:9301]], added {[Phade][8ZVecqKqQkejIfmPsH5mOQ][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-receive(from master [[Phade][8ZVecqKqQkejIfmPsH5mOQ][v-c7-es][inet[/192.168.8.81:9301]]])
[2017-04-10 16:43:30,872][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-04-10 16:43:30,872][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-04-10 16:43:30,873][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
[2017-04-10 16:46:16,192][INFO ][discovery.zen            ] [es-node1] master_left [[Phade][8ZVecqKqQkejIfmPsH5mOQ][v-c7-es][inet[/192.168.8.81:9301]]], reason [shut_down]
[2017-04-10 16:46:16,194][WARN ][discovery.zen            ] [es-node1] master left (reason = shut_down), current nodes: {[es-node1][HL4iLvfARBOk_2F-xXmGOA][v-c7-es][inet[/127.0.0.1:9300]],}
[2017-04-10 16:46:16,194][INFO ][cluster.service          ] [es-node1] removed {[Phade][8ZVecqKqQkejIfmPsH5mOQ][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-master_failed ([Phade][8ZVecqKqQkejIfmPsH5mOQ][v-c7-es][inet[/192.168.8.81:9301]])
[2017-04-10 16:46:56,236][INFO ][cluster.service          ] [es-node1] detected_master [Devil-Slayer][ucDgWFXdQqugtXw6FZvt8A][v-c7-es][inet[/192.168.8.81:9301]], added {[Devil-Slayer][ucDgWFXdQqugtXw6FZvt8A][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-receive(from master [[Devil-Slayer][ucDgWFXdQqugtXw6FZvt8A][v-c7-es][inet[/192.168.8.81:9301]]])
[2017-04-10 18:57:38,515][INFO ][discovery.zen            ] [es-node1] master_left [[Devil-Slayer][ucDgWFXdQqugtXw6FZvt8A][v-c7-es][inet[/192.168.8.81:9301]]], reason [shut_down]
[2017-04-10 18:57:38,515][WARN ][discovery.zen            ] [es-node1] master left (reason = shut_down), current nodes: {[es-node1][HL4iLvfARBOk_2F-xXmGOA][v-c7-es][inet[/127.0.0.1:9300]],}
[2017-04-10 18:57:38,515][INFO ][cluster.service          ] [es-node1] removed {[Devil-Slayer][ucDgWFXdQqugtXw6FZvt8A][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-master_failed ([Devil-Slayer][ucDgWFXdQqugtXw6FZvt8A][v-c7-es][inet[/192.168.8.81:9301]])
[2017-04-10 19:09:35,682][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:09:35,687][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:09:39,897][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:09:39,906][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:09:59,907][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:09:59,907][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:10:05,684][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:10:05,696][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:10:09,898][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:10:09,906][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:10:09,915][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:10:21,115][INFO ][node                     ] [es-node1] version[1.7.3], pid[4248], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 19:10:21,115][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 19:10:21,205][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 19:10:21,248][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 19:10:23,401][INFO ][node                     ] [es-node1] initialized
[2017-04-10 19:10:23,401][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 19:10:23,590][ERROR][bootstrap                ] [es-node1] Exception
org.elasticsearch.transport.BindTransportException: Failed to bind to [9300]
	at org.elasticsearch.transport.netty.NettyTransport.bindServerBootstrap(NettyTransport.java:422)
	at org.elasticsearch.transport.netty.NettyTransport.doStart(NettyTransport.java:283)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.transport.TransportService.doStart(TransportService.java:153)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.node.internal.InternalNode.start(InternalNode.java:257)
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:160)
	at org.elasticsearch.bootstrap.Bootstrap.main(Bootstrap.java:248)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:32)
Caused by: org.elasticsearch.common.netty.channel.ChannelException: Failed to bind to: /0.0.0.0:9300
	at org.elasticsearch.common.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:272)
	at org.elasticsearch.transport.netty.NettyTransport$1.onPortNumber(NettyTransport.java:413)
	at org.elasticsearch.common.transport.PortsRange.iterate(PortsRange.java:58)
	at org.elasticsearch.transport.netty.NettyTransport.bindServerBootstrap(NettyTransport.java:409)
	... 8 more
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss$RegisterTask.run(NioServerBoss.java:193)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue(AbstractNioSelector.java:391)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:315)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-04-10 19:10:23,603][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 19:10:23,616][INFO ][node                     ] [es-node1] stopped
[2017-04-10 19:10:23,616][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 19:10:23,619][INFO ][node                     ] [es-node1] closed
[2017-04-10 19:10:29,908][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:10:29,908][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:10:39,915][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:10:39,924][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:10:57,792][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:10:57,801][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:10:58,676][INFO ][cluster.service          ] [es-node1] detected_master [Anomaloco][dSfiJHaHRg-lbpkmI9t0ww][v-c7-es][inet[/192.168.8.81:9301]], added {[Anomaloco][dSfiJHaHRg-lbpkmI9t0ww][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-receive(from master [[Anomaloco][dSfiJHaHRg-lbpkmI9t0ww][v-c7-es][inet[/192.168.8.81:9301]]])
[2017-04-10 19:13:26,727][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 19:13:26,780][INFO ][node                     ] [es-node1] stopped
[2017-04-10 19:13:26,780][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 19:13:26,784][INFO ][node                     ] [es-node1] closed
[2017-04-10 19:33:49,448][INFO ][node                     ] [es-node1] version[1.7.3], pid[4413], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 19:33:49,448][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 19:33:49,542][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 19:33:49,569][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 19:33:51,699][INFO ][node                     ] [es-node1] initialized
[2017-04-10 19:33:51,699][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 19:33:51,850][INFO ][transport                ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/127.0.0.1:9300]}
[2017-04-10 19:33:51,868][INFO ][discovery                ] [es-node1] elasticsearch/jujxXYhPQ7uMFnQPtcsRdA
[2017-04-10 19:34:21,869][WARN ][discovery                ] [es-node1] waited for 30s and no initial state was set by the discovery
[2017-04-10 19:34:21,876][ERROR][bootstrap                ] [es-node1] Exception
org.elasticsearch.http.BindHttpException: Failed to bind to [9200]
	at org.elasticsearch.http.netty.NettyHttpServerTransport.doStart(NettyHttpServerTransport.java:269)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.http.HttpServer.doStart(HttpServer.java:89)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.node.internal.InternalNode.start(InternalNode.java:274)
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:160)
	at org.elasticsearch.bootstrap.Bootstrap.main(Bootstrap.java:248)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:32)
Caused by: org.elasticsearch.common.netty.channel.ChannelException: Failed to bind to: /0.0.0.0:9200
	at org.elasticsearch.common.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:272)
	at org.elasticsearch.http.netty.NettyHttpServerTransport$1.onPortNumber(NettyHttpServerTransport.java:260)
	at org.elasticsearch.common.transport.PortsRange.iterate(PortsRange.java:58)
	at org.elasticsearch.http.netty.NettyHttpServerTransport.doStart(NettyHttpServerTransport.java:256)
	... 7 more
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss$RegisterTask.run(NioServerBoss.java:193)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue(AbstractNioSelector.java:391)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:315)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-04-10 19:34:21,878][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 19:34:21,886][INFO ][node                     ] [es-node1] stopped
[2017-04-10 19:34:21,886][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 19:34:21,890][INFO ][node                     ] [es-node1] closed
[2017-04-10 19:36:09,572][INFO ][node                     ] [es-node1] version[1.7.3], pid[4516], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 19:36:09,572][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 19:36:09,656][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 19:36:09,680][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 19:36:11,858][INFO ][node                     ] [es-node1] initialized
[2017-04-10 19:36:11,858][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 19:36:11,927][INFO ][transport                ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/127.0.0.1:9300]}
[2017-04-10 19:36:11,936][INFO ][discovery                ] [es-node1] elasticsearch/dV2tlXErQPmYedY1OgiCfw
[2017-04-10 19:36:41,937][WARN ][discovery                ] [es-node1] waited for 30s and no initial state was set by the discovery
[2017-04-10 19:36:41,944][ERROR][bootstrap                ] [es-node1] Exception
org.elasticsearch.http.BindHttpException: Failed to bind to [9200]
	at org.elasticsearch.http.netty.NettyHttpServerTransport.doStart(NettyHttpServerTransport.java:269)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.http.HttpServer.doStart(HttpServer.java:89)
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:85)
	at org.elasticsearch.node.internal.InternalNode.start(InternalNode.java:274)
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:160)
	at org.elasticsearch.bootstrap.Bootstrap.main(Bootstrap.java:248)
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:32)
Caused by: org.elasticsearch.common.netty.channel.ChannelException: Failed to bind to: /0.0.0.0:9200
	at org.elasticsearch.common.netty.bootstrap.ServerBootstrap.bind(ServerBootstrap.java:272)
	at org.elasticsearch.http.netty.NettyHttpServerTransport$1.onPortNumber(NettyHttpServerTransport.java:260)
	at org.elasticsearch.common.transport.PortsRange.iterate(PortsRange.java:58)
	at org.elasticsearch.http.netty.NettyHttpServerTransport.doStart(NettyHttpServerTransport.java:256)
	... 7 more
Caused by: java.net.BindException: Address already in use
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss$RegisterTask.run(NioServerBoss.java:193)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue(AbstractNioSelector.java:391)
	at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:315)
	at org.elasticsearch.common.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)
	at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-04-10 19:36:41,946][INFO ][node                     ] [es-node1] stopping ...
[2017-04-10 19:36:41,954][INFO ][node                     ] [es-node1] stopped
[2017-04-10 19:36:41,954][INFO ][node                     ] [es-node1] closing ...
[2017-04-10 19:36:41,963][INFO ][node                     ] [es-node1] closed
[2017-04-10 19:44:54,543][INFO ][node                     ] [es-node1] version[1.7.3], pid[4622], build[05d4530/2015-10-15T09:14:17Z]
[2017-04-10 19:44:54,546][INFO ][node                     ] [es-node1] initializing ...
[2017-04-10 19:44:54,644][INFO ][plugins                  ] [es-node1] loaded [analysis-ik], sites [head, bigdesk]
[2017-04-10 19:44:54,670][INFO ][env                      ] [es-node1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [32.6gb], net total_space [36.9gb], types [rootfs]
[2017-04-10 19:44:56,912][INFO ][node                     ] [es-node1] initialized
[2017-04-10 19:44:56,913][INFO ][node                     ] [es-node1] starting ...
[2017-04-10 19:44:57,045][INFO ][transport                ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/127.0.0.1:9300]}
[2017-04-10 19:44:57,063][INFO ][discovery                ] [es-node1] elasticsearch/iniKINbHTAWA88LneIowZQ
[2017-04-10 19:45:27,064][WARN ][discovery                ] [es-node1] waited for 30s and no initial state was set by the discovery
[2017-04-10 19:45:27,070][INFO ][http                     ] [es-node1] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/127.0.0.1:9200]}
[2017-04-10 19:45:27,070][INFO ][node                     ] [es-node1] started
[2017-04-10 19:46:04,452][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:04,483][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:06,718][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:06,718][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:07,695][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:07,705][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:11,769][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:11,771][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:12,320][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:12,321][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:14,821][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:14,824][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:15,266][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:15,278][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:15,791][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:16,823][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:16,831][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:18,944][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:18,947][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:19,722][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:19,724][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:20,179][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:20,867][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:20,878][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:20,923][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:22,293][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:22,296][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:34,472][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:34,484][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:36,719][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:36,719][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:37,697][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:37,705][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:37,856][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:37,858][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:37,858][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:38,561][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:38,565][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:39,304][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:40,036][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:40,038][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:41,770][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:41,774][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:42,190][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:42,322][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:42,322][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:42,478][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:42,486][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:44,721][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:44,737][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:44,822][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:44,824][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:45,278][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:45,281][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:45,553][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:45,792][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:46,009][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:46,021][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:46,326][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:46,326][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:46,659][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:46,679][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:46,824][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:46,838][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:47,076][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:47,077][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:47,485][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:47,489][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:48,945][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:48,947][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:49,723][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:49,724][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:50,182][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:50,273][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:50,311][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:50,867][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:50,878][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:50,924][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:51,938][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:51,939][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:52,264][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:52,272][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:52,293][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:52,296][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:46:53,187][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:53,191][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:58,240][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:58,241][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:58,716][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:46:58,719][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:01,072][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:01,080][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:07,859][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:07,859][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:07,860][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:08,445][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:08,446][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:08,564][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:08,567][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:08,841][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:08,848][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:09,305][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:10,038][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:10,039][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:12,190][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:12,478][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:12,487][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:14,721][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:14,737][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:15,554][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:16,009][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:16,022][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:16,327][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:16,327][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:16,660][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:16,679][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:17,077][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:17,078][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:17,487][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:17,490][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:20,274][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:20,312][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:21,939][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:21,940][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:22,265][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:22,273][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:23,187][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:23,192][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:28,242][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:28,242][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:28,717][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:28,721][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:28,873][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:28,873][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:31,073][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:31,080][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:38,378][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:38,385][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:38,446][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:38,447][DEBUG][action.admin.indices.get ] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:38,841][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:38,850][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:39,817][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:39,819][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:58,874][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:58,874][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:47:59,412][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:47:59,413][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:00,196][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:00,205][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:04,853][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:04,854][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:05,448][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:05,449][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:06,259][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:06,259][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:06,939][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:06,945][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:07,163][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:08,058][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:08,062][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:08,378][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:48:08,385][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:48:08,501][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:08,502][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:09,791][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:09,797][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:09,818][DEBUG][action.admin.cluster.state] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:48:09,821][DEBUG][action.admin.cluster.health] [es-node1] observer: timeout notification from cluster service. timeout setting [30s], time since start [30s]
[2017-04-10 19:48:10,509][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:10,509][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:14,829][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:14,836][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:15,614][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:15,614][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:16,110][DEBUG][action.admin.cluster.state] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:16,120][DEBUG][action.admin.cluster.health] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:16,462][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:16,462][DEBUG][action.admin.indices.get ] [es-node1] no known master node, scheduling a retry
[2017-04-10 19:48:17,176][INFO ][cluster.service          ] [es-node1] detected_master [Kraken][lQLW9GjpSIuJFuBjUYy6-A][v-c7-es][inet[/192.168.8.81:9301]], added {[Kraken][lQLW9GjpSIuJFuBjUYy6-A][v-c7-es][inet[/192.168.8.81:9301]],}, reason: zen-disco-receive(from master [[Kraken][lQLW9GjpSIuJFuBjUYy6-A][v-c7-es][inet[/192.168.8.81:9301]]])
[2017-04-10 19:48:18,248][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/mydict.dic
[2017-04-10 19:48:18,248][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/single_word_low_freq.dic
[2017-04-10 19:48:18,279][INFO ][ik-analyzer              ] [Dict Loading]ik/custom/ext_stopword.dic
